{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file includes all data analysis done with the mouse feature datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# sk learn modules\n",
    "\n",
    "# pipeline module\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# model validation modules\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# data preprocessing modules\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# import classifier algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import regression algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Create custom classes for data transformation in the sklearn pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "\n",
    "import pingouin as pg\n",
    "# Vallat, R. (2018). Pingouin: statistics in Python. Journal of Open Source Software, 3(31), 1026,\n",
    "# https://doi.org/10.21105/joss.01026"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the mouse task analysis dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chose the file of one mouse task that you want to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "# replace mouse_task_file_name with the name of your chosen dataset for mouse feature analysis\n",
    "dataset = pd.read_csv(\"mmouse_task_file.csv\", sep=\"\\t\", encoding=\"utf-8\", index_col=\"ID\")\n",
    "\n",
    "# choose the task_name of the file\n",
    "# Important: do not change the task_name string, it must match the string of the task name appended to each mouse\n",
    "# feature in the file, e.g. mean_speed_PointClick\n",
    "task_name = \"PointClick\"\n",
    "# task_name = \"DragDrop\"\n",
    "# task_name = \"Slider\"\n",
    "# task_name = \"FollowCircle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before the analysis, do some transformations to the task names for later steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the non_features to be handable by the custom transformer (bad solution, but the \"fastest\" at the point it\n",
    "# was done --> The data need the same name structure to be able to transform it correctly in later analysis steps\n",
    "dataset.rename(columns={\n",
    "    \"Pr_arousal\": \"arousal_Pr_\" + task_name,\n",
    "    \"Pr_valence\": \"valence_Pr_\" + task_name,\n",
    "    \"Co_valence\": \"valence_Con_\" + task_name,\n",
    "    \"Co_arousal\": \"arousal_Con_\" + task_name,\n",
    "    \"Pr_stress\": \"stress_Pr_\" + task_name,\n",
    "    \"Co_stress\": \"stress_Con_\" + task_name,\n",
    "    \"Pr_MDBF_GS\": \"MDBF_GS_Pr_\" + task_name,\n",
    "    \"Pr_MDBF_RU\": \"MDBF_RU_Pr_\" + task_name,\n",
    "    \"Pr_MDBF_WM\": \"MDBF_WM_Pr_\" + task_name,\n",
    "    \"Co_MDBF_GS\": \"MDBF_GS_Con_\" + task_name,\n",
    "    \"Co_MDBF_RU\": \"MDBF_RU_Con_\" + task_name,\n",
    "    \"Co_MDBF_WM\": \"MDBF_WM_Con_\" + task_name\n",
    "}, inplace=True)\n",
    "\n",
    "# get the names of all input features\n",
    "all_names = list(dataset.columns)\n",
    "\n",
    "# get a list with all non mouse features\n",
    "non_features = [\"arousal_Pr_\" + task_name, \"valence_Pr_\" + task_name, \"valence_Con_\" + task_name,\n",
    "                \"arousal_Con_\" + task_name, \"MDBF_GS_Pr_\" + task_name, \"MDBF_RU_Pr_\" + task_name,\n",
    "                \"MDBF_WM_Pr_\" + task_name, \"MDBF_GS_Con_\" + task_name, \"MDBF_RU_Con_\" + task_name,\n",
    "                \"MDBF_WM_Con_\" + task_name, \"stress_Pr_\" + task_name, \"stress_Con_\" + task_name,\n",
    "                \"jahr\", \"sex\", \"schule\", \"condition\"]\n",
    "\n",
    "# get a list with the names of the mouse features and the name of the condition and practice phase string\n",
    "mouse_feature_names = []\n",
    "condition_name_string, practice_name_string = None, None\n",
    "for name in all_names:\n",
    "\n",
    "    if name not in non_features:\n",
    "\n",
    "        if \"Pr_\" in name:\n",
    "            mouse_feature_names.append(name[:name.find(\"Pr_\")])\n",
    "            condition_name_string = name[name.find(\"Pr_\"):]\n",
    "        elif \"Con_\" in name:\n",
    "            practice_name_string = name[name.find(\"Con_\"):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some descriptive statistics about the mouse usage features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the descriptive stats of all independent variables variables\n",
    "\n",
    "# get the data from the high stress condition, drop the non dependent variables, get the descriptive stats and sort\n",
    "# it by column name\n",
    "# entire sample\n",
    "descriptive_hs_data = dataset.loc[dataset[\"condition\"] == 0].drop(non_features, axis=1).describe().sort_index(axis=1)\n",
    "descriptive_ls_data = dataset.loc[dataset[\"condition\"] == 1].drop(non_features, axis=1).describe().sort_index(axis=1)\n",
    "\n",
    "# save the descriptive stats as an excel file\n",
    "with pd.ExcelWriter(\"Descriptive_Data_Mouse_Usage_\" + task_name + \".xlsx\") as writer:\n",
    "    descriptive_hs_data.to_excel(writer, sheet_name=\"High_Stress_Condition\")\n",
    "    descriptive_ls_data.to_excel(writer, sheet_name=\"Low_Stress_Condition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create histograms of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mouse usage features\n",
    "\n",
    "for i, col in enumerate(dataset.columns):\n",
    "    if col not in non_features:\n",
    "        plt.figure(i)\n",
    "        sns.distplot(dataset[col], kde=False)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dependent variables\n",
    "for i, col in enumerate(non_features):\n",
    "    plt.figure(i)\n",
    "    sns.distplot(dataset[col], kde=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a Pairplot to plot different variables against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a plot with all possible variables is too much, therefore plot selected variables\n",
    "# an example:\n",
    "some_features = [i + condition_name_string for i in mouse_feature_names[:1]]\n",
    "some_features.extend([\"valence_Con_\" + task_name, \"arousal_Con_\" + task_name])\n",
    "data_to_plot = dataset.loc[:, some_features]\n",
    "\n",
    "sns.pairplot(data_to_plot)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate mixed anovas for each mouse usage feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### same procedure as in the manipulation check, but with the mouse usage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dataset for the ANOVA\n",
    "\n",
    "# helper to split the prepare the dataset for the anova and change the data from a wide to a long format\n",
    "def create_anova_df(df, variable, condition, practice):\n",
    "\n",
    "    # assign a subject number to each subject\n",
    "    df[\"subject\"] = np.arange(len(df))\n",
    "    # replace the condition number with a string\n",
    "    df[\"condition\"].replace({0: \"HS\", 1: \"LS\"}, inplace=True)\n",
    "\n",
    "    # change the format\n",
    "    df = pd.melt(df, id_vars=[\"subject\", \"condition\"], value_vars=[variable + practice, variable + condition],\n",
    "                 var_name=\"Pr-Con\", value_name=variable)\n",
    "\n",
    "    # change the name of the column to practice and condition for clearer reading of the results\n",
    "    df[\"Pr-Con\"].replace({variable + practice: \"Pr\", variable + condition: \"Con\"}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PointPlots to visualize the manipulation check results\n",
    "# Tutorial here: https://raphaelvallat.com/pingouin.html\n",
    "def plot_anova(data, variable):\n",
    "\n",
    "    # data visualization\n",
    "    sns.set()\n",
    "    sns.pointplot(data=data, x=\"Pr-Con\", y=variable, hue=\"condition\", dodge=True, markers=['o', 's'],\n",
    "                  capsize=.1, errwidth=1, palette='colorblind')\n",
    "\n",
    "    plt.title(\"Pointplot with \" + variable)\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    # save the plot\n",
    "    # plt.savefig('ANOVA' + variable + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the anova results\n",
    "\n",
    "def calc_anova(data, variable):\n",
    "\n",
    "    # calculate the anova\n",
    "    aov = pg.mixed_anova(dv=variable, within=\"Pr-Con\", between=\"condition\", subject=\"subject\", data=data)\n",
    "    print(\"Repeated measures ANOVA with \" + variable)\n",
    "    pg.print_table(aov)\n",
    "    posthocs = pg.pairwise_ttests(dv=variable, within='Pr-Con', between='condition',\n",
    "                                  subject='subject', data=data)\n",
    "    pg.print_table(posthocs)\n",
    "    print(\"\\n\" + \"\\n\")\n",
    "\n",
    "    # return the anova and post hoc dataframes with an added index layer that is the variable name\n",
    "    return pd.concat([aov], keys=[variable]), pd.concat([posthocs], keys=[variable])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get a dataframe with all anova results per task\n",
    "def get_anova_results(dataframe, variable_list, condition, practice):\n",
    "\n",
    "    # initialize dataframes\n",
    "    anova_df = pd.DataFrame()\n",
    "    posthoc_df = pd.DataFrame()\n",
    "\n",
    "    # loop the variable list and add the result dataframes to the initialized dataframes\n",
    "    for variable in variable_list:\n",
    "\n",
    "        anova_data = create_anova_df(dataframe, variable, condition, practice)\n",
    "\n",
    "        # plot the anova\n",
    "        # plot_anova(anova_data, variable)\n",
    "        # calc the anova\n",
    "        anova, posthoc = calc_anova(anova_data, variable)\n",
    "\n",
    "        anova_df = pd.concat([anova_df, anova])\n",
    "        posthoc_df = pd.concat([posthoc_df, posthoc])\n",
    "\n",
    "    return anova_df, posthoc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ANOVA for all mouse features and save the results in a dataframe\n",
    "# entire sample\n",
    "anova_results_df, anova_posthocs_df = get_anova_results(dataset, mouse_feature_names, condition_name_string,\n",
    "                                                        practice_name_string)\n",
    "\n",
    "# save the descriptive stats as an excel file\n",
    "with pd.ExcelWriter(\"ANOVAS_Mouse_Parameters_\" + task_name + \".xlsx\") as writer:\n",
    "    anova_results_df.to_excel(writer, sheet_name=\"mixed_ANOVA_Results\")\n",
    "    anova_posthocs_df.to_excel(writer, sheet_name=\"POSTHOC_Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Class for custom variable transformation in the sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStandardization(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    \"\"\"\n",
    "    does custom transformation on the condition data by using the practice data to take individual differences into\n",
    "    account\n",
    "    1. use the difference between the condition and practice trial\n",
    "    2. only use the condition trial\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method=\"ignore_practice\"):\n",
    "        self.method = method\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        feat_names = []\n",
    "        cond_name_string, pra_name_string = None, None\n",
    "        for col in list(X.columns):\n",
    "            if \"Pr_\" in col:\n",
    "                feat_names.append(col[:col.find(\"Pr_\")])\n",
    "                pra_name_string = col[col.find(\"Pr_\"):]\n",
    "            elif \"Con_\" in col:\n",
    "                cond_name_string = col[col.find(\"Con_\"):]\n",
    "\n",
    "        if self.method == \"ignore_practice\":\n",
    "\n",
    "            # get only the names of the condition columns\n",
    "            condition_cols = [col for col in list(X.columns) if \"Con_\" in col]\n",
    "\n",
    "            return X.loc[:, condition_cols]\n",
    "\n",
    "        elif self.method == \"Difference\":\n",
    "\n",
    "            # calculate the difference between the condition phase and baseline data\n",
    "            diff_df = pd.DataFrame()\n",
    "            for feat in feat_names:\n",
    "                diff_df[\"Diff_\" + feat] = X[feat + cond_name_string] - X[feat + pra_name_string]\n",
    "\n",
    "            return diff_df\n",
    "\n",
    "        else:\n",
    "\n",
    "            print(\"Chosen method \" + self.method + \" does not exist. Defaulted to ignore_practice\")\n",
    "            return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condition Classification Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permuation test helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the results of 5-fold cross validation followed by a permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates a k-fold cross val score and compares the mean performance score with a distribution of n models that\n",
    "# were trained with permutated class labels\n",
    "# more information can be found here:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.permutation_test_score.html\n",
    "def ml_permutation_test(iv, dv, standard_method, algorithm, procedure_title):\n",
    "\n",
    "    # save the results of the permutation test\n",
    "    results = {}\n",
    "\n",
    "    # make a pipeline that does the preprocessing and outputs the cross validation score\n",
    "    pipeline = Pipeline([\n",
    "        (\"custom_transformation\", CustomStandardization(method=standard_method)),\n",
    "        (\"robust_scaler\", RobustScaler()),\n",
    "        (\"clf\", algorithm)\n",
    "    ])\n",
    "\n",
    "    # create a stratified kFold Splitter\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # get the mean cross validation score, the permuation scores and the\n",
    "    # p-value of the permutation test\n",
    "    score, permutation_scores, pvalue = permutation_test_score(\n",
    "        pipeline, iv, dv, scoring=\"accuracy\", cv=cv, n_permutations=500, n_jobs=1)\n",
    "\n",
    "    # get the statistical values of the permutation\n",
    "    perm_score = np.mean(permutation_scores)\n",
    "    perm_std = np.std(permutation_scores)\n",
    "    # Get the significance threshold (the classification model must be better than 95% of the permutated models)\n",
    "    sig_tresh = np.percentile(permutation_scores, 95.0)\n",
    "\n",
    "    results[\"Mean_score\"] = np.round(score, 2) * 100\n",
    "    # results[\"Std_score\"] = np.round(std, 2) * 100\n",
    "    results[\"p_value\"] = np.round(pvalue, 5)\n",
    "    results[\"Mean_Permutation_score\"] = np.round(perm_score, 2) * 100\n",
    "    results[\"Std_Permutation_score\"] = np.round(perm_std, 2) * 100\n",
    "    results[\"Sig_Treshold\"] = sig_tresh * 100\n",
    "\n",
    "    plot_permutation_test_results(permutation_scores * 100,\n",
    "                                  score * 100, np.round(pvalue, 3),\n",
    "                                  np.round(sig_tresh, 2) * 100, procedure_title)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the permutation test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results of the permutation procedure\n",
    "def plot_permutation_test_results(permutation_scores, score, pvalue, p_tresh, plot_title):\n",
    "    # Create and save a plot of the procedure\n",
    "    plt.hist(permutation_scores, bins=np.arange(np.min(permutation_scores), np.max(permutation_scores), 1),\n",
    "             alpha=0.6, rwidth=1.0, edgecolor=\"black\", color=\"Blue\")\n",
    "    ylim = plt.ylim()\n",
    "    plt.plot(2 * [score], ylim, \"--r\", linewidth=3,\n",
    "             label=\"Mean Accuracy: %s, p = %s\" % (np.round(np.mean(score), 2), pvalue))\n",
    "    plt.plot(2 * [p_tresh], ylim, \"--b\", linewidth=2, label=\"Sig. Threshold: \" \"%s\" % p_tresh)\n",
    "    plt.plot(2 * [np.mean(permutation_scores)], ylim, \"--g\", linewidth=3,\n",
    "             label=\"Mean Permutation Score: \" \"%s\" % (np.round(np.mean(permutation_scores), 2)))\n",
    "    plt.ylim(ylim)\n",
    "    plt.xlabel(\"Accuracy Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(plot_title)\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    \n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    # save the plot\n",
    "#     plt.savefig(\"Permutation_Test_\" + plot_title + \".png\")\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the classification model options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with all the different model options that the models can be build and tested in a loop\n",
    "# the options are:\n",
    "#   - Using the logistic regression, the support vector machine or the random forest algorithm\n",
    "#   - Control for baseline mouse usage or ignore the practice data\n",
    "# other options can be added or options can be removed\n",
    "\n",
    "model_options = {\n",
    "    \"Alg\": {\n",
    "        \"LogRegr\": LogisticRegression(solver=\"liblinear\"),\n",
    "        \"SVM\": SVC(gamma=\"scale\"),\n",
    "        \"RF\": RandomForestClassifier(n_estimators=50)},\n",
    "    \"Pr_inclusion\": {\n",
    "        \"Ignore\": \"ignore_practice\",\n",
    "        \"Diff\": \"Difference\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the permuation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permuation Test (caution, this procedure takes long to run, because every classification option is additionally\n",
    "# done 500 times on permutated class labels)\n",
    "\n",
    "# get a dict to save the classifier results:\n",
    "\n",
    "permutation_results = {}\n",
    "\n",
    "# get the predictors\n",
    "predictors = dataset.drop(non_features, axis=1)\n",
    "class_label = dataset[\"condition\"]\n",
    "\n",
    "# loop over the classification options and save the results of the classification\n",
    "for option in model_options[\"Pr_inclusion\"]:\n",
    "    for alg in model_options[\"Alg\"]:\n",
    "        print(\"Permutation test classification with Mouse Data and \" + option + alg)\n",
    "        permutation_results[(option, alg)] = \\\n",
    "                    ml_permutation_test(predictors,\n",
    "                                        class_label,\n",
    "                                        model_options[\"Pr_inclusion\"][option],\n",
    "                                        model_options[\"Alg\"][alg],\n",
    "                                        \"Permutation Test with \" + option + \" \" + alg)\n",
    "\n",
    "# create a multiindexed dataframe from the results dictionary\n",
    "permutation_results_df = pd.DataFrame(permutation_results).T\n",
    "\n",
    "# Save the results\n",
    "permutation_results_df.to_excel(\"Classification_Permutation_Test_Results_\" + task_name + \".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on Valence and Arousal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-fold-cross validation helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a k-fold cross validation for regression\n",
    "def k_fold_cross_val_regression(iv, dv, standard_method, algorithm):\n",
    "\n",
    "    # save the results\n",
    "    results = {}\n",
    "\n",
    "    # make a pipeline that does the preprocessing and outputs the cross validation score\n",
    "    pipeline = Pipeline([\n",
    "        (\"custom_transformation\", CustomStandardization(method=standard_method)),\n",
    "        (\"robust_scaler\", RobustScaler()),\n",
    "        (\"clf\", algorithm)\n",
    "    ])\n",
    "\n",
    "    # get a cross validation splitter\n",
    "    cv = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "    metrics = {\"nMAE\": \"neg_mean_absolute_error\", \"R2_score\": \"r2\"}\n",
    "\n",
    "    scores = cross_validate(pipeline, iv, dv, cv=cv, scoring=metrics, return_train_score=True)\n",
    "\n",
    "    for key in scores:\n",
    "        results[\"mean_\" + key] = np.round(np.mean(scores[key]), 5)\n",
    "        results[\"std_\" + key] = np.round(np.std(scores[key]), 5)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the regression model options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary that holds all information about the different options of the regression analysis\n",
    "# (Similar to the classification)\n",
    "\n",
    "# Regression on valence and arousal\n",
    "sam_regression_options = {\n",
    "    \"Alg\": {\n",
    "        \"LinReg\": LinearRegression(),\n",
    "        \"RFReg\": RandomForestRegressor(n_estimators=50),\n",
    "        \"SVR\": SVR(gamma=\"auto\")}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function to save the regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the item name and information about baseline inclusion are passed as parameters to the helper function\n",
    "def get_self_report_regression_results(item_name, handle_practice):\n",
    "    \n",
    "    sam_regression_results = {}\n",
    "\n",
    "    # get the predictors (mouse usage features)\n",
    "    predictors = dataset.drop(non_features, axis=1)\n",
    "    # get the self-report item\n",
    "    if \"Con\" in item_name:\n",
    "        # only use the condition valence/arousal score\n",
    "        dependent_variable = dataset[item_name]\n",
    "    else:\n",
    "        # use the valence/arousal difference score between the condition and practice phase\n",
    "        dependent_variable = dataset[item_name + \"_Con_\" + task_name] \\\n",
    "                                 - dataset[item_name + \"_Pr_\" + task_name]\n",
    "    \n",
    "    # loop over the regression options\n",
    "    for alg in sam_regression_options[\"Alg\"]:\n",
    "        print(\"Regression with 5foldCV and \" + item_name + alg)\n",
    "        sam_regression_results[(item_name, alg)] = \\\n",
    "                        k_fold_cross_val_regression(iv=predictors,\n",
    "                                                    dv=dependent_variable,\n",
    "                                                    standard_method=handle_practice,\n",
    "                                                    algorithm=sam_regression_options[\"Alg\"][alg])\n",
    "\n",
    "\n",
    "    # create a multiindexed dataframe from the results dictionary\n",
    "    sam_regression_results_df = pd.DataFrame(sam_regression_results).T\n",
    "    \n",
    "    return sam_regression_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the analysis for each dependent variable and save the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression without including the baseline of the practice phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM prediction\n",
    "# take the sam items of the condition phase\n",
    "sam_items = [\"valence_Con_\" + task_name, \"arousal_Con_\" + task_name]\n",
    "\n",
    "# intiate an empty dataframe\n",
    "self_report_reg_no_baseline = pd.DataFrame()\n",
    "\n",
    "for item in sam_items:\n",
    "    # calculate the results of the regression analysis\n",
    "    results = get_self_report_regression_results(item_name=item, handle_practice=\"ignore_practice\")\n",
    "    # save them into the dataframe\n",
    "    self_report_reg_no_baseline = pd.concat([self_report_reg_no_baseline, results])\n",
    "\n",
    "# save the dataset\n",
    "self_report_reg_no_baseline.to_excel(\"Reggression_Results_No_Baseline\" + task_name + \".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regression that includes the baseline of the practice phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also use the practice data and predict the difference score between the practice and actual condition\n",
    "# get the dataset\n",
    "\n",
    "# The MDBF Items could be added here (to make the table even bigger :))\n",
    "sam_items = [\"valence\", \"arousal\"]\n",
    "\n",
    "# save the results\n",
    "self_report_reg_baseline = pd.DataFrame()\n",
    "\n",
    "for item in sam_items:\n",
    "    # get the results\n",
    "    results = get_self_report_regression_results(item_name=item, handle_practice=\"Difference\")\n",
    "    # save the results in a dataframe\n",
    "    self_report_reg_baseline = pd.concat([self_report_reg_baseline, results])\n",
    "\n",
    "self_report_reg_baseline.to_excel(\"Difference_Score_Reggression_Results_\" + task_name + \".xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task versus Task classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-and-Click Task versus Drag-and-Drop Task\n",
    "\n",
    "# import and read the datasets\n",
    "\n",
    "# Replace the dataset file names with your dataset filenames (and directory)\n",
    "pointclick_data = pd.read_csv(\"point_click_task_dataset.csv\", sep=\"\\t\", encoding=\"utf-8\", index_col=\"ID\")\n",
    "dragdrop_data = pd.read_csv(\"drag_drop_task_dataset.csv\", sep=\"\\t\", encoding=\"utf-8\", index_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the condition column names (only of the condition, not the practice)\n",
    "pointclick_cols = [i for i in list(pointclick_data.columns) if \"Con_PointClick\" in i]\n",
    "dragdrop_cols = [i for i in list(dragdrop_data.columns) if \"Con_DragDrop\" in i]\n",
    "\n",
    "# get a list with the new shared column names (name doesnt include the task name anymore, only the feature name, e.g.\n",
    "# mouse_speed_mean)\n",
    "renamed_cols = [i[:-len(\"Con_PointClick\")] for i in pointclick_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframes with the relevant columns, rename the column and add a \"task indicator\" (classification prediction)\n",
    "pointclick_data = pointclick_data.loc[:, pointclick_cols]\n",
    "pointclick_data.columns = renamed_cols\n",
    "pointclick_data[\"task\"] = 0\n",
    "\n",
    "dragdrop_data = dragdrop_data.loc[:, dragdrop_cols]\n",
    "dragdrop_data.columns = renamed_cols\n",
    "dragdrop_data[\"task\"] = 1\n",
    "\n",
    "# merge the two dataframes to one\n",
    "pc_vs_dd = pd.concat([pointclick_data, dragdrop_data], axis=0)\n",
    "\n",
    "# check if everything worked as intended\n",
    "print(\"Point-Click-Data shape:\", pointclick_data.shape)\n",
    "print(\"Drag-Drop-Data shape:\", dragdrop_data.shape)\n",
    "print(\"Merged Dataset shape\", pc_vs_dd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the predictors and the dependent variable\n",
    "X = pc_vs_dd.drop([\"task\"], axis=1)\n",
    "Y = pc_vs_dd[\"task\"]\n",
    "\n",
    "# create a pipeline with the scaler and the machine learning algorithm (here support vector classification is used\n",
    "# exmeplarly)\n",
    "pipeline = Pipeline([\n",
    "        (\"robust_scaler\", RobustScaler()),\n",
    "        (\"clf\", SVC(gamma=\"scale\"))\n",
    "    ])\n",
    "\n",
    "# get the scores from 5-fold-cross validation\n",
    "task_vs_task_scores = cross_val_score(pipeline, X, Y, cv=5)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-----------\")\n",
    "print(\"Mean Accuracy in the Task Versus Task Classification (5-fold-cv): \", np.mean(task_vs_task_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:full_conda]",
   "language": "python",
   "name": "conda-env-full_conda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
